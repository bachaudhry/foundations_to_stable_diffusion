{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f676cc4-bbd5-4440-b310-fcb1e385a28e",
   "metadata": {},
   "source": [
    "# **Mini Batch Training for MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c79cf2-95a9-442e-a250-b72d2f337628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, math, os, time, shutil\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.test import  test_close\n",
    "from pathlib import Path\n",
    "\n",
    "# Configs\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=3, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=3, linewidth=125)\n",
    "\n",
    "# Path setup\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "# Loading MNIST data as tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff73b2-644b-440e-b17d-e77da6044a76",
   "metadata": {},
   "source": [
    "## **Initial Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a1d4a-5b07-41e5-85e2-1b3942a0c4ca",
   "metadata": {},
   "source": [
    "### **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196455b3-48c1-468c-9169-8239bb421768",
   "metadata": {},
   "source": [
    "Copying over the starting cells from the previous NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0c897c-1bd8-45fd-b7c3-bf49501109e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50\n",
    "\n",
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cce843-3bae-41e6-95fe-ce2713be873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349c4b70-ee05-4966-b992-ee7374689db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh,  10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a952a6-ce01-4fce-9f43-1a48125b127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.091, -0.212, -0.082,  ..., -0.028,  0.006,  0.061],\n",
       "        [-0.073, -0.136, -0.143,  ...,  0.030,  0.043,  0.145],\n",
       "        [-0.186, -0.036,  0.018,  ..., -0.008, -0.003,  0.022],\n",
       "        ...,\n",
       "        [-0.026, -0.215, -0.038,  ..., -0.010,  0.090,  0.139],\n",
       "        [-0.099, -0.094, -0.046,  ..., -0.011,  0.018,  0.108],\n",
       "        [-0.033, -0.251, -0.064,  ...,  0.005,  0.030,  0.138]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114894b6-6128-4c2e-927f-a45d92fa3945",
   "metadata": {},
   "source": [
    "### **Cross Entropy Loss: Improving The Loss Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3b87-8ce6-4a6e-a393-b90c42ce010b",
   "metadata": {},
   "source": [
    "We need to improve our loss function from before. Instead of outputting 1 number per image, we will now have 10 one-hot-encoded numbers per image.\n",
    "\n",
    "The basic formula for Log Softmax is:\n",
    "\n",
    "$$\n",
    "\\log \\text{Softmax}(x_i) = \\log (\\frac{e^{x_i}}{\\sum_{x_j} e^{x_j}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb69627-8cd9-410f-b834-9db67fa003a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a793025d-65b5-487c-8b91-88b9ae19661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad7d82-9266-426d-8371-8a4f2df983f7",
   "metadata": {},
   "source": [
    "Using the formula: $$ \\log\\left(\\frac{a}{b}\\right) = \\log(a) - \\log(b)$$ allows us to simplify the `log_softmax()` function further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30aea25b-d0d4-4b32-993c-5caecadb47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the log rule above and x.exp().log() = x since exp() and log() cancel out.\n",
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18c5f0-021d-4639-b7b0-bfa6f3a56fa1",
   "metadata": {},
   "source": [
    "Also, we can simplify things even further by using the [LogSumExp](https://en.wikipedia.org/wiki/LogSumExp) trick.\n",
    "\n",
    "This allows us to compute the log of the sum of exponentials in a more \"stable\" way i.e. it prevents numerical underflow or overflow when dealing with log probabilities. The mathematical representation for this is:\n",
    "\n",
    "$$\n",
    "\\log \\sum_{i} e^{x_i} = a + \\log \\sum_{i} e^{x_i - a}\n",
    "$$ \n",
    "\n",
    "where $a = \\max(x_i)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57afe8a4-b33b-468a-96d3-37b03378ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    # Taking the max on the last dim\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b09f0b3-6e24-41cb-aea3-568463afe12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting log_softmax() using logsumexp() from PyTorch\n",
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d532b6fc-777a-4660-9587-e377626e4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1a09c-1ba3-4f6d-9e96-86af54fde523",
   "metadata": {},
   "source": [
    "The interesting fact is that Cross Entropy, in Machine Learning, is also expressed as the **[Negative Log Likelihood Loss](https://chris-said.io/2020/12/26/two-things-that-confused-me-about-cross-entropy/)**.\n",
    "\n",
    "So, the cross entropy loss above can be rewritten as the :\n",
    "\n",
    "$$\n",
    "- \\sum x \\log p(x)\n",
    "$$\n",
    "\n",
    "We can index into our 1-hot encoded x's using PyTorch's (and, NumPy's) advanced indexing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b182ed25-ae42-4bef-9e57-4f52e46503cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick a sample\n",
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e70482-d00e-475d-8ddd-fe856dab33b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.200, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.372, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.355, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the positioning of the indices\n",
    "sm_pred[0, 5], sm_pred[1, 0], sm_pred[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d2bf08-1595-4978-a62a-8ca0bcb93370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.200, -2.372, -2.355], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The indexing method allows us to get these values as \n",
    "# To recap, [0,1,2] are row indices. This 'fancy' indexing basically\n",
    "# takes elements from 0th row and column specified by 0th element of y_train\n",
    "# The same applies for other values in the list.\n",
    "sm_pred[[0, 1, 2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf8c44b-aca5-4b35-bc87-53d9aabe7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating negative log likelihood loss\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c3092e-6af7-4860-b19a-f2e311c3b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.300, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06609e4-e736-4e04-839f-e4b8513d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch's version\n",
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63a61b-193b-4e60-a394-debc19db0a36",
   "metadata": {},
   "source": [
    "`F.log_softmax` and `F.nll_loss` are combined in one function called `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99465b6e-191d-40d8-839b-0aa2c0dfa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474341a-57d9-40f4-bf4d-2a758df71470",
   "metadata": {},
   "source": [
    "## **Basic Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92fd557-abd0-43f1-9477-9c8c01fddca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our loss function\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8224c0aa-f856-4bca-9f8f-86f9f42e91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.091, -0.212, -0.082,  0.096, -0.035,  0.082, -0.042, -0.028,  0.006,  0.061], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50               # batch size\n",
    "\n",
    "xb = x_train[0 : bs]  # Mini batch from training data\n",
    "preds = model(xb)     \n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402e6fbc-73d2-4013-a23c-47b3bb782b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
       "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking our target, matching the mini-batch size\n",
    "yb = y_train[0 : bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af71020-c66a-4daa-b4c4-280f2522bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.305, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the loss function\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96825fe-ac46-400b-9bbd-933d4e07d998",
   "metadata": {},
   "source": [
    "Lets find the index of the highest number for each of our 64 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9898f02a-d345-42dd-aa4e-164aa4484f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3,\n",
       "        9, 3, 5, 3, 8, 3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7f3497-9fdc-4e2c-a6db-abcf92d13e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.080)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the accuracy of our predictions\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()\n",
    "\n",
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba660fd-d1e2-4f99-b376-11bde0300159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a learning rate and number of epochs\n",
    "lr = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4176e717-4661-4567-afbe-6dbffe73a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print loss and accuracy after each epoch\n",
    "def report(loss, preds, yb): print(f'{loss:.3f}, {accuracy(preds, yb):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b460bd3-1b88-422b-b512-b0f8c6b18211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305, 0.080\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6272f4b8-986c-48a7-ab11-53a2f632a883",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115, 0.980\n",
      "0.124, 0.940\n",
      "0.082, 0.960\n"
     ]
    }
   ],
   "source": [
    "# Our training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs)) # Create a slice from x_i to x_n or equivalent to bs\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        # Backward pass\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_() #inplace zeroing\n",
    "                    l.bias  .grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed494f-46c8-451c-90f4-2c72e4462207",
   "metadata": {},
   "source": [
    "## **Using Parameters and Optim**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e2054-9b39-4d16-84f6-d1bf7b650154",
   "metadata": {},
   "source": [
    "### **Parameters**\n",
    "\n",
    "Lets rebuild the `nn.Module` class to get a better understanding of whats going on under the hood before implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f018db-6c2f-4e13-94cd-e3596393dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using PyTorch's nn.Module class and assigning an attribute which is a linear layer\n",
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(in_features=3, out_features=4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a6daa-0584-41e6-b741-fc4603293341",
   "metadata": {},
   "source": [
    "We can see each of the items or `named_children` (which is an generator function) in the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d06ec6f-7694-481f-ac9d-f86cbf12d2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066e7d3-6637-4b46-817b-d66e66b4ec85",
   "metadata": {},
   "source": [
    "We can list the parameters of the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "640c9552-a7a4-4e1c-b09d-c389d0c39118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.568,  0.431, -0.300],\n",
       "         [ 0.126, -0.321, -0.238],\n",
       "         [ 0.508,  0.038,  0.218],\n",
       "         [ 0.131, -0.170, -0.237]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.011, -0.511, -0.392,  0.560], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a3aa4-eda8-4dcf-ba0a-a7d248966192",
   "metadata": {},
   "source": [
    "So, this makes it possible for the `nn.Module` class to inherit attributes when we create model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45fcff00-8f62-4d84-939b-cb47ad74a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # Inputs, outputs and a single NH layer\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    # As before, we will use the refactor forward() function instead of __call()__ to let\n",
    "    # PyTorch handle all gradient calcs.\n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c80c6736-9c30-438c-8d81-30c6d26633ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling each layer of the model.\n",
    "model = MLP(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b5a6ae-fe46-4e01-9ccb-48d4d633e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "# Listing all the attributes\n",
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeabc137-c12e-43ee-84bd-2c1dc64f6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# And listing all the parameters\n",
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5667684-6d33-43bf-8117-b5087e1e563c",
   "metadata": {},
   "source": [
    "Since PyTorch can handle all the attributes and parameters for us, we can rewrite the training loop from the earlier section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cadf4ae-b56e-441c-8c84-ad18cb743a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "# Training loop as a function\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            #pdb.set_trace()\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            #Updated section, we no longer need to explicitly call each layer's updates\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "885bcc11-57f0-4e49-b6b8-a0a0fef5bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.187, 0.960\n",
      "0.112, 0.960\n",
      "0.045, 1.000\n"
     ]
    }
   ],
   "source": [
    "# Running the training loop function\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f263ff-ec2b-48b0-855d-1c70657de940",
   "metadata": {},
   "source": [
    "The inheritance class makes things extremely streamlined when constructing models, but how does it really work its magic?\n",
    "\n",
    "At the heart of the action is PyTorch overriding the `__setattr__` function in `nn.Module`. [Python's official documentation](https://docs.python.org/3/library/functions.html) defines it as:\n",
    "\n",
    "> ... the counterpart of `getattr()`. The arguments are an object, a string, and an arbitrary value. The string may name an existing attribute or a new attribute. The function assigns the value to the attribute, provided the object allows it. For example, `setattr(x, 'foobar', 123)` is equivalent to `x.foobar = 123`.\n",
    "\n",
    "Lets rebuild `nn.Module` as a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de5febca-8f24-4310-b806-cb1aab30a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule: # Not having () after the class name is equivalent to calling MyModule(object)\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {} # Dictionary for storing named children\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v): # Automatically called when we set attributes in the class\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v) # Ensure attributes are set\n",
    "\n",
    "    def __repr__(self): return f'{self._modules}' # Return string of dict created above\n",
    "\n",
    "    def parameters(self):\n",
    "        # We can use the yield shortcut to return values from an iterator instead of looping through it.\n",
    "        for l in self._modules.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44078e9a-c38b-4b9b-866c-c1c0cff56675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MyModule(m, nh, 10)\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ccfda-72da-4ed2-a599-64632216b74d",
   "metadata": {},
   "source": [
    "The rest of the functionality works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdc49aed-f9fc-482d-9a2a-f929fe0a85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mod.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387f519-952d-4c7d-a94a-2777de121650",
   "metadata": {},
   "source": [
    "Now that we have successfully recreated `nn.Module`, we will also need to save or _register_ the various layers of our model. This needs to happen all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9745a-5140-4170-934c-9e1f50c472f0",
   "metadata": {},
   "source": [
    "### **Registering Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e6a60f2-9862-4c15-9c25-79b4539c12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753d97b-4c67-4100-a2bc-7287dd79899c",
   "metadata": {},
   "source": [
    "Lets create a list of all the layers of our model, which we can then pass to a subclass of `nn.Module` i.e. `Model`. This approach is generally used to build sequential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef5b1dff-f69e-4e9b-9e5e-b177596a0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f41e420a-bd53-4c51-9bdc-82cb0b1a398c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers # Store the list of layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "\n",
    "    def forward(self, x): return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "428e303f-0330-4f1b-9fbf-14fc55660e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reference, reduce \"applies a function of two arguments cumulatively to the items of a sequence\n",
    "# or iterable, from left to right, so as to reduce the iterable to a single value.\"\"\n",
    "reduce(lambda x, y: x+y, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b928a1b-b096-4bd8-8deb-39daaef56590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6041426-cef1-40ae-8a0a-e84d874f6a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592007f-b389-4c87-b31e-1a728e6b2ebd",
   "metadata": {},
   "source": [
    "### **nn.ModuleList**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2423d73-f65e-4829-980b-1fb729741f5f",
   "metadata": {},
   "source": [
    "Passing the list of Layers is already handled by `nn.ModuleList`. Reverting to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "851f889b-e36d-422f-9992-8a8e6f36a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x): # Reductions: reduce() works the same as this block, and is widely used for sequential models\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "678cac11-b74a-43e8-b6bb-7df45f965d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9f0774e-7d59-436b-bf09-db5c5442cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.119, 0.960\n",
      "0.109, 0.960\n",
      "0.075, 0.980\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9472d-3db4-449f-8f8b-de684fecdaa9",
   "metadata": {},
   "source": [
    "### **nn.Sequential**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12aec7-f5c0-4dba-907d-7182fe414231",
   "metadata": {},
   "source": [
    "`Sequential` has also been recreated above, so we can revert to PyTorch's `nn.Sequential` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e467f96-1cc8-4978-b6b5-150037355962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5988fe57-b60b-4799-81ad-2de4bcf81176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164, 0.940\n",
      "0.128, 0.960\n",
      "0.076, 0.960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.026, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ad7d638-a227-4a3b-a9b0-2ad1cfeadd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbb804-f73e-4c1c-bc29-cfe9f91160b9",
   "metadata": {},
   "source": [
    "### **Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e427e3a-8e4d-455c-a7fa-42117f58f9d0",
   "metadata": {},
   "source": [
    "The `Optimizer` cycles through the parameters and updates them using the gradients and the learning rate. This class also sets the gradients to zero after each backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfbf98ec-b603-4667-9305-7731d6f982ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params, self.lr = list(params), lr # Since params might be a generator\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33db8c71-8240-47e8-8ae2-2f4564bcb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model using Sequential from before.\n",
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "# Creating the optimizer\n",
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb8c58a5-de40-4027-bb67-f6c4e98cbe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.176, 0.940\n",
      "0.126, 0.960\n",
      "0.114, 0.940\n"
     ]
    }
   ],
   "source": [
    "# Here's an even more updated version of the training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        # Updates \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799eaa60-f396-4421-a983-0e3ef3f5bc00",
   "metadata": {},
   "source": [
    "At this point, we've effectively created an `SGD` optimizer. That means we can use PyTorch's version from here on out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c02120c0-4b30-48de-be1c-6600f9bc23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e160bb-65b0-44e5-8fb0-832d25f87b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    # Passing the model's parameters to PyTorch's SGD optimizer\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ccdeb30-7a31-42b6-b516-712870be71d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.326, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a1e7e7e-64e6-414b-a089-b74d7256e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118, 0.980\n",
      "0.085, 0.980\n",
      "0.075, 0.980\n"
     ]
    }
   ],
   "source": [
    "# Re-running the training loop again, this time Pytorch has us covered with its classes for the model and optim.\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d89f21-54e8-49cf-a308-c2e85c2a8f75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The code could do with additional refactoring, especially where data handling is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8243-56f5-46d2-a65f-e1441d24d304",
   "metadata": {},
   "source": [
    "## **Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b146b-7fff-4c31-b6ce-5f6372e102a1",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bfe8f-585d-4028-95f6-f44acb0617a2",
   "metadata": {},
   "source": [
    "Handling minibatches of x and y values separately is not optimal. A class which handles mini-batches and additional data related functionality is the obvious next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db4d445a-c96a-4390-92c8-7a33947fcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self): return len(self.x) # Length of the dataset\n",
    "\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i] # Grab items, return a tuple of (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae68044d-7daa-4810-8e79-580489c0e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataset\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "# Ensuring the sizes match\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6059a366-2bd5-4f96-805b-0d3ff50d2ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([50000]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a737e5c-4948-4abe-b757-850f2af79e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([50000]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding in the entire data set gives us\n",
    "xb, yb = train_ds[:]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df94f6b5-3fd6-47ef-b653-1c06c974cb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking a much smaller sample\n",
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)\n",
    "\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af290c-ac52-4373-abe8-207db10a9241",
   "metadata": {},
   "source": [
    "PyTorch also handles datasets this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98bdad33-7f5d-4a01-9f79-53a5b83ef541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.165, 0.960\n",
      "0.110, 0.940\n",
      "0.085, 0.960\n"
     ]
    }
   ],
   "source": [
    "# Creating the model again\n",
    "model, opt = get_model()\n",
    "\n",
    "# Re-running the training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        # Updated data handling\n",
    "        xb, yb = train_ds[i : min(n, i+bs)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac073a-4ec8-4d54-bad0-57b6a4728bbf",
   "metadata": {},
   "source": [
    "The for loop handling the data loading part of the loop can also be refactored away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b75ed4-5861-44a3-8504-6c27be34fba8",
   "metadata": {},
   "source": [
    "### **DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f645387-35b9-409a-808d-d58c4d029190",
   "metadata": {},
   "source": [
    "Instead of looping over batches, we can use a dataloader to further simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4edc6690-4f12-403f-9072-1cd722069655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "\n",
    "    def __iter__(self): # The iterator handles looping through the batches and items.\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d17c7922-b20f-4181-8f66-7d87bec2ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.DataLoader at 0x7f9ba39b01f0>,\n",
       " <__main__.DataLoader at 0x7f9ba39b3460>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)\n",
    "\n",
    "train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b29c3f7f-03a6-4da2-b418-6c181886fffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl)) # Iterate through the dataloader object and grab items \n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b68550d-d6c8-46da-b7fc-551ebdf8916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7,\n",
       "        6, 8, 9, 0, 3, 8, 3, 7, 7, 8, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking yb\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a70ec404-ed1c-4a7c-bd5b-dea47d3d3ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the first element of the x batch\n",
    "plt.imshow(xb[0].view(28, 28));\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96d7a5d6-e099-41bc-bfa3-bf828fcb653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, reloading the model, the optim and updating the training loop with the new \n",
    "# dataloader implementation\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl: # Already loaded\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e70b973-3a49-4f33-aaec-5c59104a7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.085, 0.960\n",
      "0.109, 0.960\n",
      "0.071, 0.960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.043, grad_fn=<NllLossBackward0>), tensor(0.980))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be955320-5ba8-406c-a5b6-2c72833cfc06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **Random Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b790b-aee8-4640-8fb9-3e4d8b6020db",
   "metadata": {},
   "source": [
    "At present, our training datasets retain their original order. So we will need to introduce an additional set of features to ensure that we are carrying out random sampling with every training iteration.\n",
    "\n",
    "This goes without saying, but validation data should **not be randomized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f7084d9-3ab3-453c-919b-a70e1987e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09981a25-3189-4cb3-ac89-360d78faa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sampler \n",
    "class Sampler():\n",
    "    # Setting shuffle's default to False will return ordered items in the iterator below.\n",
    "    def __init__(self, ds, shuffle=False): self.n, self.shuffle = len(ds), shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res) # Shuffle defaults to False\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd0e03d8-2dcc-4b17-ae17-1ee7093d00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b156412-27c6-43f8-b2b9-1d8292652699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sampler at 0x7f9b9e19a0e0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our Sampler without suffle\n",
    "ss = Sampler(train_ds)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31471205-b9c9-4c63-96f6-3df4f190b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Lets iterate through the sampler\n",
    "it = iter(ss)\n",
    "for o in range(10): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f929db0-4244-4056-bf8e-cccdde9c727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use islice from before\n",
    "list(islice(ss, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc0fa6e7-b1e8-4d71-85f9-170e6d0efdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36664, 34273, 13818, 27717, 17802, 28274, 15688, 24744, 18048, 23001]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the iterator to shuffle\n",
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62180e0d-b231-40ba-846f-3b9cca473903",
   "metadata": {},
   "source": [
    "Instead of running `list(islice())` every time, or having to specify our batch ordering, we can create a `BatchSampler` to handle all the slicing and dicing for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "664e499e-0134-4b58-a123-9076f22954cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f02ee5a-a6ec-45f4-b2e2-34d24442a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "\n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7ceca2c-8f3e-4bed-a70b-e14beb0eb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstore_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mstore_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Store params named in comma-separated `names` from calling context into attrs in `self`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'self'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mstore_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstore_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__slots__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mstore_args\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__stored_args__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stored_args__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0manno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcast\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', *'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__slots__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0madded\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', *'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbut\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_store_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniforge3/lib/python3.10/site-packages/fastcore/basics.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? fc.store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5d9acc1-52ca-439c-8016-11ca9c785d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25340, 26171, 32046, 41149, 1379, 20466],\n",
       " [25650, 26951, 19012, 17936, 35645, 2314],\n",
       " [5261, 36611, 13702, 27895, 10165, 24925],\n",
       " [24623, 18208, 40674, 35985, 5423, 6822],\n",
       " [13835, 38145, 26063, 13067, 13035, 40667]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = BatchSampler(ss, 6) # Create mini batches of 6 items per MB\n",
    "list(islice(batch, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0bd90-d62d-4ca6-89e6-da16c6438673",
   "metadata": {},
   "source": [
    "We will now need a **collation** function to update the `DataLoader` from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6eea52ab-0cca-471a-94c0-1e6cb56a7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    # Heavily used in PyTorch and HuggingFace to ensure that the lists of items can be used as inputs for\n",
    "    # our models.\n",
    "    xs, ys = zip(*b) # Zip all elements in a list\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c34c780-6610-4012-8699-b04d61ffd074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the DataLoader class\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, batch, collate_fn=collate): fc.store_attr()\n",
    "\n",
    "    # Loop through the collated data and return batches\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9659508a-4f8e-4bc1-be72-b0c48802eb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.BatchSampler at 0x7f9b9e26aa40>,\n",
       " <__main__.BatchSampler at 0x7f9b9e2689d0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation batches\n",
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)\n",
    "\n",
    "train_samp, valid_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817c1f2-3a96-4692-aa10-21daa003497c",
   "metadata": {},
   "source": [
    "What is collate actually doing under the hood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc91e3cc-048e-47de-8433-653ad41f520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements (randomized): 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[27088,\n",
       " 42340,\n",
       " 42291,\n",
       " 27940,\n",
       " 24782,\n",
       " 31046,\n",
       " 29698,\n",
       " 13350,\n",
       " 12642,\n",
       " 15454,\n",
       " 41916,\n",
       " 40087,\n",
       " 19445,\n",
       " 13924,\n",
       " 25523,\n",
       " 22245,\n",
       " 43015,\n",
       " 41259,\n",
       " 42698,\n",
       " 15269,\n",
       " 2520,\n",
       " 30478,\n",
       " 2213,\n",
       " 7189,\n",
       " 19673,\n",
       " 27927,\n",
       " 33829,\n",
       " 31695,\n",
       " 21365,\n",
       " 32881,\n",
       " 7026,\n",
       " 7352,\n",
       " 31808,\n",
       " 31661,\n",
       " 29896,\n",
       " 29304,\n",
       " 3555,\n",
       " 33294,\n",
       " 33644,\n",
       " 46049,\n",
       " 18761,\n",
       " 7477,\n",
       " 1808,\n",
       " 38086,\n",
       " 10589,\n",
       " 48106,\n",
       " 42418,\n",
       " 49784,\n",
       " 20268,\n",
       " 48962]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets pick some samples since we've already created train_samp. This will give us a randomized list of indices\n",
    "o = next(iter(train_samp))\n",
    "print(f'Number of elements (randomized): {len(o)}'); o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc790b45-b1a2-4421-999f-9b05505a7aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.156, 0.617, 0.004,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.352, 0.906, 0.051, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.555, 0.750, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.039, 0.395, 0.105, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.555, 0.750, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.234, 0.992, 0.406, 0.000, 0.000, 0.000, 0.000, 0.000, 0.797, 0.750, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.035, 0.777, 0.906, 0.055, 0.000, 0.000, 0.000, 0.000, 0.000, 0.883, 0.609, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.082, 0.992, 0.625, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.168, 0.969, 0.426, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.234, 0.992, 0.406, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.215, 0.992, 0.383, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.410, 0.992, 0.277, 0.000, 0.000, 0.000, 0.000, 0.000, 0.215, 0.992, 0.098, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.250, 0.992, 0.879, 0.215, 0.000, 0.000, 0.000, 0.000, 0.270, 0.992, 0.098, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.070, 0.949, 0.992, 0.973,\n",
       "         0.785, 0.508, 0.234, 0.184, 0.730, 0.992, 0.430, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.145, 0.617, 0.953, 0.992, 0.992, 0.992, 0.992,\n",
       "         0.992, 0.992, 0.684, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.102, 0.395, 0.723, 0.781, 0.781, 0.969, 0.793, 0.055, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.574, 0.766, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.539, 0.766, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.840, 0.766, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.668, 0.766, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.539, 0.832, 0.031, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.539, 0.996, 0.098, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.328, 0.992, 0.203, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,\n",
       "         0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000]),\n",
       " tensor(4))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of tensors from the indices above\n",
    "p = [train_ds[i] for i in o]\n",
    "# Pick a single element\n",
    "p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d6cc4-f789-4575-8502-6e7b0bbd30d7",
   "metadata": {},
   "source": [
    "So we get a list of both x and y tensors. We then stack them together after calling `zip()`. This allows us to prep x and y so that they can be used as inputs for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1454a3ce-3a92-4008-888e-247fbbcd89be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4),\n",
       " tensor(6),\n",
       " tensor(8),\n",
       " tensor(6),\n",
       " tensor(1),\n",
       " tensor(6),\n",
       " tensor(2),\n",
       " tensor(4),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(2),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(8),\n",
       " tensor(3),\n",
       " tensor(0),\n",
       " tensor(4),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(4),\n",
       " tensor(8),\n",
       " tensor(7),\n",
       " tensor(3),\n",
       " tensor(2),\n",
       " tensor(8),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(3),\n",
       " tensor(8),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(8),\n",
       " tensor(5),\n",
       " tensor(2),\n",
       " tensor(6),\n",
       " tensor(1),\n",
       " tensor(8),\n",
       " tensor(4),\n",
       " tensor(3),\n",
       " tensor(5),\n",
       " tensor(8),\n",
       " tensor(7),\n",
       " tensor(5),\n",
       " tensor(2),\n",
       " tensor(4))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys = zip(*p)\n",
    "# We will now have tuples of index 0 and index 1 elements.\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc0a5e5f-d9e4-400c-851b-247a8ffa318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 8, 6, 1, 6, 2, 4, 1, 0, 2, 3, 3, 8, 3, 0, 4, 0, 5, 6, 4, 8, 7, 3, 2, 8, 6, 0, 5, 3, 8, 7, 0, 0, 3, 3, 8, 5, 2,\n",
       "        6, 1, 8, 4, 3, 5, 8, 7, 5, 2, 4])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking\n",
    "torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b0d6bab-fea2-4131-a863-4512219b1110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.DataLoader at 0x7f9b9df96fe0>,\n",
       " <__main__.DataLoader at 0x7f9b9e269660>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataloaders from the samples.\n",
    "train_dl = DataLoader(train_ds, batch=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch=valid_samp)\n",
    "\n",
    "train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e9e97e2-348c-4678-8fbe-065df59eb3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verifying\n",
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[1].view(28, 28))\n",
    "yb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b08c8850-8a98-4709-add5-3b86f326e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "611a665d-e74b-4bbf-a661-85cec9e7d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100, 0.100\n",
      "0.083, 0.040\n",
      "0.028, 0.140\n"
     ]
    }
   ],
   "source": [
    "# Verifying that our dataloader and sampler are working\n",
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37deb504-38ac-4b26-ad7c-bf8f150e0e20",
   "metadata": {},
   "source": [
    "The steps above cover almost all of PyTorch's DataLoader functionality. So this is a really important bit of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238809a-a81a-442b-a35d-8cbdd678f48e",
   "metadata": {},
   "source": [
    "### **Multi-Processing DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45537b65-7718-402b-a035-0505ee23ee98",
   "metadata": {},
   "source": [
    "Here is a quick and hacky way to implement multi-processing in our workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "939aff82-0c35-45ed-bd97-5fff722c5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b4de983-8468-4a48-90f6-3d4b2f842178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 1, 0]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing into our dataset is the same as calling __getitem__() below.\n",
    "train_ds[[4, 8, 6, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e734828a-88cb-461a-a2be-71a4d36407f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 1, 0]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([4, 8, 6, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02e78a-f143-4434-bb00-22f020ec561d",
   "metadata": {},
   "source": [
    "We will use map to call `__getitem__()` on our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b8df8941-057c-4c78-988d-374e05cdb573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([9, 2]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([4, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# Calling __getitem__() on each item in some random batches\n",
    "for o in map(train_ds.__getitem__, ([4, 5], [9, 3], [6, 1])): print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fe79c-3a7e-4c83-98b0-04d5715dcf29",
   "metadata": {},
   "source": [
    "The addition of **Pooling** will allow parallel processing on our DataLoader class. So, in effect, the `__getitem__()` function above will be called on multiple batches in parallel. \n",
    "\n",
    "Bear in mind that the first batch will be slower than subsequent batches due to the overhead involved in firing up the multi-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea144e51-acc7-4126-8d21-ebdbd2b7db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batches, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "\n",
    "    def __iter__(self): # Pool allows us to use multiprocessing\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, iter(self.batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c59d592c-2337-4935-8846-f90da8141498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 s  60.1 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_dl = DataLoader(train_ds, batches=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e400537-6e36-4fba-a559-54e0a02bf939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21 s  57.6 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_dl = DataLoader(train_ds, batches=train_samp, n_workers=4)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "da47e2d4-60ca-4d35-bbb6-f2e52b5a2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 s  30.7 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_dl = DataLoader(train_ds, batches=train_samp, n_workers=-1)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740471a-e627-4d36-9727-1e5dbb36a704",
   "metadata": {},
   "source": [
    "### **PyTorch DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede6bce9-8a40-486e-9e4a-0d75b17f5e48",
   "metadata": {},
   "source": [
    "Implementing custom multi-processing will require lots more code, but the previous section does a fair job of explaining the basics.\n",
    "\n",
    "Using PyTorch's own dataloaders and samplers now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55adb685-6e03-47b0-9ae3-3ee3e84c43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c9694a10-5583-493b-9d2e-915c786472b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4adfe9fa-c108-432d-b9df-8229085451ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "454272e4-ef58-4493-b87b-ef295e27ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109, 0.120\n",
      "0.068, 0.200\n",
      "0.041, 0.200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.031, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b7858-80a4-4ae5-b190-b52824010afe",
   "metadata": {},
   "source": [
    "We will be calling `BatchSampler` quite frequently, so PyTorch can auto-generate it for us. This further reduces the number of steps involved in creating data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84e304b0-6029-41f5-94b0-ffb77d6980ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sampler argument auto-wraps BatchSampler into it's call\n",
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17b9ca-dbdd-4178-8496-f29b05fc4902",
   "metadata": {},
   "source": [
    "We can opt to move away from calling `RandomSampler()` and `SequentialSampler()` by setting `shuffle=True/False` in the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29691d0c-9f0e-4a7f-b1e5-0d08fa06b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "905cb827-285d-4efc-8d13-603e2d83de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116, 0.120\n",
      "0.058, 0.120\n",
      "0.131, 0.100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.105, grad_fn=<NllLossBackward0>), tensor(0.980))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f59ec-06f2-40b2-b596-0f566a68557e",
   "metadata": {},
   "source": [
    "An **important** point to note is that our datasets know how to grab multiple indeces at once, so we can just use the `BatchSampler` as _the_ sampler.\n",
    "\n",
    "The `BatchSampler` ensures that the data comes pre-collated. We will be diving into this is greater detail in future NBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d6469e2-114e-484e-864e-f0e3715e5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "75f148ee-ecf1-4cb8-90a9-feb913d64a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea53c8-07c6-43e5-ac4b-5b63ccb6bf20",
   "metadata": {},
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c4245-7170-42c4-a8cf-e0e42e1f3b7d",
   "metadata": {},
   "source": [
    "The validation steps can be added directly to the training loop / function. We need to be mindful that `model.train()` is called before training and `model.eval()` before inference to ensure that all the layers of the model behave as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3946c482-cdf5-4838-8bcd-b893cbe50e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Set training steps\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval() # Set evaluation/validation steps\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0., 0., 0\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred, yb).item()* n # sum up the loss\n",
    "                tot_acc += accuracy(pred, yb).item()* n # sum up the accuracies\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aaa609a9-6cbc-484a-a1ce-0dc873b562fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs)),\\\n",
    "           (DataLoader(valid_ds, batch_size=bs*2, shuffle=False, **kwargs)) # Doubling the batch size for validation DL since we aren't \n",
    "                                                                     # running backprop and won't be consuming the extra memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "81ae1869-2127-4267-aefb-3cbb31d2cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now get our dataloaders and fit the model in 3 lines of code!!\n",
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "31718dfb-08b8-4cdd-83fc-fe93a2761141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15938209020532668 0.9529000061750412\n",
      "1 0.12813590691424906 0.9623000061511994\n",
      "2 0.11384968753904104 0.967700006365776\n",
      "3 0.12138134432956577 0.965000005364418\n",
      "4 0.11025585792958736 0.970400008559227\n",
      "CPU times: user 27.5 s, sys: 218 ms, total: 27.7 s\n",
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%time loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2a7da-3c6e-42ec-84b7-454c07b0b463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
